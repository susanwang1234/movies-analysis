{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jia Yi (Susan) Wang\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import re\n",
    "#import seaborn\n",
    "#seaborn.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\"\"\"\"from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\"\"\"\n",
    "\n",
    "\"\"\"from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\"\"\"\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\"\"\"\"from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\"\"\"\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import TruncatedSVD #PCA for sparse values\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/genres.json.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cc1b40a3b133>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/genres.json.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0momdb_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/omdb-data.json.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrt_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/rotten-tomatoes.json.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwd_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/wikidata-movies.json.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\susan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m     )\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\susan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    648\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chunksize can only be passed if lines=True\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\susan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m             )\n\u001b[0;32m    695\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\susan\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\susan\\appdata\\local\\programs\\python\\python37-32\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\susan\\appdata\\local\\programs\\python\\python37-32\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/genres.json.gz'"
     ]
    }
   ],
   "source": [
    "genres = pd.read_json('../data/genres.json.gz', orient='record', lines=True, encoding='utf-8')\n",
    "omdb_data = pd.read_json('..data/omdb-data.json.gz', orient='record', lines=True, encoding='utf-8')\n",
    "rt_data = pd.read_json('data/rotten-tomatoes.json.gz', orient='record', lines=True, encoding='utf-8')\n",
    "wd_data = pd.read_json('data/wikidata-movies.json.gz', orient='record', lines=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb_data=omdb_data.explode('omdb_genres')\n",
    "omdb_data=omdb_data[omdb_data.omdb_awards.notnull()]\n",
    "omdb_data=omdb_data[omdb_data.omdb_awards!='N\\A']\n",
    "\n",
    "nominations_re = re.compile(r'Nominated for (\\d+)')\n",
    "nominations_re2 = re.compile(r'(\\d+) nomination(s?)')\n",
    "wins_re = re.compile(r'(\\d+) win(s?)')\n",
    "wins_re2 = re.compile(r'Won (\\d+)')\n",
    "\n",
    "def get_wins(txt):\n",
    "    wins = 0\n",
    "    wins1 = wins_re.search(txt)\n",
    "    wins2 = wins_re2.search(txt)\n",
    "    if wins1:\n",
    "        wins = wins + int(wins1.group(1))\n",
    "    if wins2:\n",
    "        wins = wins + int(wins2.group(1))\n",
    "    return wins\n",
    "\n",
    "def get_nominations(txt):\n",
    "    noms = 0\n",
    "    nominations1 = nominations_re.search(txt)\n",
    "    nominations2 = nominations_re2.search(txt)\n",
    "    if nominations1:\n",
    "        noms = noms + int(nominations1.group(1))\n",
    "    if nominations2:\n",
    "        noms = noms + int(nominations2.group(1))\n",
    "    return noms\n",
    "\n",
    "omdb_data['nominations'] = omdb_data['omdb_awards'].apply(get_nominations)\n",
    "omdb_data['wins'] = omdb_data['omdb_awards'].apply(get_wins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=np.inf)\n",
    "#set(omdb_data.omdb_awards)\n",
    "omdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_data = wd_data.explode('cast_member')\n",
    "movies_played=wd_data[['cast_member','wikidata_id']].groupby('cast_member').count().reset_index().rename(columns={'wikidata_id':'movies_in'})\n",
    "wd_data_stars = movies_played[movies_played.movies_in>=10]\n",
    "wd_data_stars = wd_data_stars.set_index('cast_member').join(wd_data.set_index('cast_member'),on='cast_member').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_data_stars #filter out actors who < 10 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = omdb_data.set_index('imdb_id').join(rt_data.set_index('imdb_id'),on='imdb_id')\n",
    "joined = joined.join(wd_data_stars.set_index('imdb_id'), lsuffix='_joined', rsuffix='_wd', on='imdb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our Features and Labels and filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['audience_average', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.audience_average.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoder example: https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "#Column Transforer source: https://datascience.stackexchange.com/questions/41113/deprecationwarning-the-categorical-features-keyword-is-deprecated-in-version\n",
    "\n",
    "#Encoding the genres to binary\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ") #randomforestregressor - try this\n",
    "\n",
    "#X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegessor model for predicting audience average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingRegressor(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['audience_average'],axis=1)\n",
    "y=info['audience_average']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) \n",
    "\n",
    "#For actors that starred in >1 movie:\n",
    "#m_d=5: train=0.3398654, valid=0.33893729 15.3 s\n",
    "#m_d=6: train=0.37, valid=0.36 20.3s\n",
    "#m_d=7: train=0.40, valid=0.39 23.3s\n",
    "#m_d=8: train=0.42, valid=0.40 30.7s\n",
    "#m_d=9: train=0.45, valid=0.43 34.1s\n",
    "#m_d=10 : train=0.46, valid=0.44 44.4s\n",
    "#m_d=15 : train=0.53, valid=0.47 1min37s\n",
    "#m_d=20 : train=0.55, valid=0.47 2min55s\n",
    "#m_d=30 : train=0.57, valid=0.46 4min48s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model for predicting critic average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['critic_average', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.critic_average.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingRegressor(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['critic_average'],axis=1)\n",
    "y=info['critic_average']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model for predicting audience percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['audience_percent', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.audience_percent.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingRegressor(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['audience_percent'],axis=1)\n",
    "y=info['audience_percent']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model for predicting critic percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['critic_percent', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.critic_percent.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingRegressor(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['critic_percent'],axis=1)\n",
    "y=info['critic_percent']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model for predicting if a movie profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['made_profit', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.made_profit.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingClassifier(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['made_profit'],axis=1)\n",
    "y=info['made_profit']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
