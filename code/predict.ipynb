{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jia Yi (Susan) Wang\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import re\n",
    "#import seaborn\n",
    "#seaborn.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\"\"\"\"from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\"\"\"\n",
    "\n",
    "\"\"\"from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\"\"\"\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\"\"\"\"from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\"\"\"\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import TruncatedSVD #PCA for sparse values\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = pd.read_json('../data/genres.json.gz', orient='record', lines=True, encoding='utf-8')\n",
    "omdb_data = pd.read_json('../data/omdb-data.json.gz', orient='record', lines=True, encoding='utf-8')\n",
    "rt_data = pd.read_json('../data/rotten-tomatoes.json.gz', orient='record', lines=True, encoding='utf-8')\n",
    "wd_data = pd.read_json('../data/wikidata-movies.json.gz', orient='record', lines=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb_data=omdb_data.explode('omdb_genres')\n",
    "omdb_data=omdb_data[omdb_data.omdb_awards.notnull()]\n",
    "omdb_data=omdb_data[omdb_data.omdb_awards!='N\\A']\n",
    "\n",
    "nominations_re = re.compile(r'Nominated for (\\d+)')\n",
    "nominations_re2 = re.compile(r'(\\d+) nomination(s?)')\n",
    "wins_re = re.compile(r'(\\d+) win(s?)')\n",
    "wins_re2 = re.compile(r'Won (\\d+)')\n",
    "\n",
    "def get_wins(txt):\n",
    "    wins = 0\n",
    "    wins1 = wins_re.search(txt)\n",
    "    wins2 = wins_re2.search(txt)\n",
    "    if wins1:\n",
    "        wins = wins + int(wins1.group(1))\n",
    "    if wins2:\n",
    "        wins = wins + int(wins2.group(1))\n",
    "    return wins\n",
    "\n",
    "def get_nominations(txt):\n",
    "    noms = 0\n",
    "    nominations1 = nominations_re.search(txt)\n",
    "    nominations2 = nominations_re2.search(txt)\n",
    "    if nominations1:\n",
    "        noms = noms + int(nominations1.group(1))\n",
    "    if nominations2:\n",
    "        noms = noms + int(nominations2.group(1))\n",
    "    return noms\n",
    "\n",
    "omdb_data['nominations'] = omdb_data['omdb_awards'].apply(get_nominations)\n",
    "omdb_data['wins'] = omdb_data['omdb_awards'].apply(get_wins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_data = wd_data.explode('cast_member')\n",
    "movies_played=wd_data[['cast_member','wikidata_id']].groupby('cast_member').count().reset_index().rename(columns={'wikidata_id':'movies_in'})\n",
    "wd_data_stars = movies_played[movies_played.movies_in>=10]\n",
    "wd_data_stars = wd_data_stars.set_index('cast_member').join(wd_data.set_index('cast_member'),on='cast_member').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = omdb_data.set_index('imdb_id').join(rt_data.set_index('imdb_id'),on='imdb_id')\n",
    "joined = joined.join(wd_data_stars.set_index('imdb_id'), lsuffix='_joined', rsuffix='_wd', on='imdb_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our Features and Label and filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['audience_average', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.audience_average.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoder example: https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "#Column Transforer source: https://datascience.stackexchange.com/questions/41113/deprecationwarning-the-categorical-features-keyword-is-deprecated-in-version\n",
    "\n",
    "#Encoding the genres to binary\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ") #randomforestregressor - try this\n",
    "\n",
    "#X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegessor model for predicting audience average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3592728220649418\n",
      "0.3517942806093531\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingRegressor(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['audience_average'],axis=1)\n",
    "y=info['audience_average']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) \n",
    "\n",
    "#For actors that starred in >1 movie:\n",
    "#m_d=5: train=0.3398654, valid=0.33893729 15.3 s\n",
    "#m_d=6: train=0.37, valid=0.36 20.3s\n",
    "#m_d=7: train=0.40, valid=0.39 23.3s\n",
    "#m_d=8: train=0.42, valid=0.40 30.7s\n",
    "#m_d=9: train=0.45, valid=0.43 34.1s\n",
    "#m_d=10 : train=0.46, valid=0.44 44.4s\n",
    "#m_d=15 : train=0.53, valid=0.47 1min37s\n",
    "#m_d=20 : train=0.55, valid=0.47 2min55s\n",
    "#m_d=30 : train=0.57, valid=0.46 4min48s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model for predicting critic average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41721040718106905\n",
      "0.4139857008989343\n"
     ]
    }
   ],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['critic_average', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.critic_average.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingRegressor(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['critic_average'],axis=1)\n",
    "y=info['critic_average']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model for predicting audience percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3876440710817455\n",
      "0.38018352115317644\n"
     ]
    }
   ],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['audience_percent', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.audience_percent.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingRegressor(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['audience_percent'],axis=1)\n",
    "y=info['audience_percent']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model for predicting critic percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3523301274375591\n",
      "0.3415297391033797\n"
     ]
    }
   ],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['critic_percent', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.critic_percent.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingRegressor(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['critic_percent'],axis=1)\n",
    "y=info['critic_percent']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model for predicting if a movie profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946959214601041\n",
      "0.9422810832180273\n"
     ]
    }
   ],
   "source": [
    "info = joined.reset_index()\n",
    "info = info[['made_profit', 'omdb_genres', 'cast_member', 'wins', 'nominations', 'country_of_origin']]\n",
    "info = info[info.made_profit.notnull()]\n",
    "info = info[info.cast_member.notnull()]\n",
    "info = info[info.omdb_genres.notnull()]\n",
    "info = info[info.omdb_genres != 'N/A']\n",
    "info = info[info.country_of_origin.notnull()]\n",
    "info = info[info.country_of_origin != 'N/A']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), [0,1,4])\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "        #steps=[('col_trans',ct), ('lr', LinearRegression(fit_intercept=False))]\n",
    "        steps=[\n",
    "            ('col_trans',ct), \n",
    "            ('pca', TruncatedSVD(2)), \n",
    "            ('gfr', GradientBoostingClassifier(max_depth=5, n_estimators=100, min_samples_leaf=10))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X=info.drop(columns=['made_profit'],axis=1)\n",
    "y=info['made_profit']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_valid,y_valid)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
